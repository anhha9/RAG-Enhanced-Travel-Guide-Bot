{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RAG-Enhanced LLM for Travel Guide Conversational Application\n",
    "\n",
    "In this code file, I will build the conversational application from scratch. In other words, I will increase the features added to the conversational application. At the beginning, the vanilla application is based on the parametric knowledge of the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the environment through OpenAI's API\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#from langchain import HuggingFaceHub\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "#retrieving api key\n",
    "key=os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Application Without RAG and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's great! Kyoto is a city full of rich history and culture, with plenty of amazing attractions to explore. Here's a suggested itinerary for you to make the most of your day in Kyoto:\n",
      "\n",
      "Morning:\n",
      "1. Start your day at Fushimi Inari Taisha, known for its iconic red torii gates. It's best to visit early in the morning to avoid crowds and enjoy the serene atmosphere.\n",
      "2. After exploring Fushimi Inari Taisha, head to Gion district, a traditional area of Kyoto famous for its historic streets, tea houses, and geisha culture. Stroll around Hanamikoji Street and explore the charming shops and cafes.\n",
      "\n",
      "Lunch:\n",
      "3. Enjoy a traditional Japanese lunch at a local restaurant in Gion or nearby Pontocho Alley. Try some local delicacies such as kaiseki (multi-course meal) or sushi.\n",
      "\n",
      "Afternoon:\n",
      "4. Visit Kiyomizu-dera Temple, a UNESCO World Heritage site with stunning views of Kyoto. Don't miss the iconic wooden stage that offers a panoramic view of the city.\n",
      "5. Explore the Higashiyama District, a preserved historic area with narrow streets, traditional machiya houses, and souvenir shops. You can also visit Kodai-ji Temple and Yasaka Shrine in this area.\n",
      "\n",
      "Evening:\n",
      "6. End your day by visiting Arashiyama district, known for its bamboo groves, scenic river views, and the famous Togetsukyo Bridge. You can also visit the beautiful Tenryu-ji Temple and the peaceful Arashiyama Bamboo Forest.\n",
      "\n",
      "Remember to check the opening hours of the attractions and plan your day accordingly. Have a wonderful time exploring Kyoto!\n"
     ]
    }
   ],
   "source": [
    "# Define and manage prompts for the LLM\n",
    "# Especially this helps the output to be more conversational. Without this, the output will be concise and rigid, even robot-like\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# Represent the messages in a structured format\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "# Build and execute chains of language models\n",
    "from langchain.chains import LLMChain, ConversationChain  # passes input to an LLM and returns the output; manage and maintain conversational history\n",
    "from langchain.chat_models import ChatOpenAI  # Choose OpenAI's LLM (default to GPT-3.5-turbo)\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "# SystemMessage defines the tone of the assistant. You can make the assistant helpful or angry with just the SystemMessage\n",
    "# HumanMessage can be any question you want to ask the assistant\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful and attentive assistant that help the user to plan an optimized itinerary.\"),\n",
    "    HumanMessage(content=\"I will have one free day in Kyoto. What should I do to best enjoy myself?\")\n",
    "]\n",
    "output = chat(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "With just one sentence contain the time I can have in Kyoto (1 day) and one question asking for advice, the conversational application can generate a whole itinery from morning until evening, which includes very famous Kyoto destinations (such as Kiyomizu-dera). However, often we do not end a conversation with just 1 turn of interaction. Normally, as we have more information and we start to link the information with our wants, needs, and curiosity, we will ask more questions based on the previous interactions and context in the conversation. In this case, we need the bot to have a memory so that we can optimize the travel plans based on our likings and conditions and the bot's previous suggestions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Application With Memory\n",
    "\n",
    "Note that the bot will only start to have a memory after including these specific code (in the next box). The conversation I had in the previous section will not be included in the memory of the conversational application created in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1383/3004699516.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/tmp/ipykernel_1383/3004699516.py:11: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n",
      "/tmp/ipykernel_1383/3004699516.py:17: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  conversation.run(\"What should I do in Kyoto if I just have one day?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What should I do in Kyoto if I just have one day?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"There are so many amazing things to do in Kyoto in just one day! I would recommend starting your day by visiting the iconic Fushimi Inari Shrine with its thousands of red torii gates. Then, you can head to Kiyomizu-dera Temple for stunning views of the city. Don't forget to try some traditional Kyoto cuisine like matcha green tea and kaiseki ryori for lunch. In the afternoon, you can explore the historic Gion district and maybe even catch a glimpse of a geisha. Finally, end your day with a relaxing stroll through the beautiful Arashiyama Bamboo Grove. Enjoy your day in Kyoto!\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConversationBufferMemory stores the entire conversation history (both user inputs and AI responses) in a buffer\n",
    "# It allows the chatbot to maintain context across multiple exchanges.\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# ConversationChain connects a language model (LLM) to a memory component, \n",
    "# enabling contextual conversations over multiple turns\n",
    "from langchain.chains import ConversationChain  \n",
    "\n",
    "# verbose=True for easier debugging if needed\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, verbose=True, memory=memory\n",
    ")\n",
    "\n",
    "# Run a conversation with run. You need to call this every time you want to interact with the bot\n",
    "# This helps with: missing context in memory, incorrect formatting of the user input, unintended behavior due to chain logic\n",
    "conversation.run(\"What should I do in Kyoto if I just have one day?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What should I do in Kyoto if I just have one day?\n",
      "AI: There are so many amazing things to do in Kyoto in just one day! I would recommend starting your day by visiting the iconic Fushimi Inari Shrine with its thousands of red torii gates. Then, you can head to Kiyomizu-dera Temple for stunning views of the city. Don't forget to try some traditional Kyoto cuisine like matcha green tea and kaiseki ryori for lunch. In the afternoon, you can explore the historic Gion district and maybe even catch a glimpse of a geisha. Finally, end your day with a relaxing stroll through the beautiful Arashiyama Bamboo Grove. Enjoy your day in Kyoto!\n",
      "Human: I visited Kyomizu-dera before. I want to focus my day for the best cuisine in Kyoto. Give me some suggestions.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"If you're looking to focus on the best cuisine in Kyoto, I would recommend trying out some of the following options:\\n\\n1. Kaiseki Ryori: This traditional multi-course meal is a must-try in Kyoto. It typically features seasonal and local ingredients prepared in a beautifully presented manner.\\n\\n2. Yudofu: A simple yet delicious dish made with tofu simmered in a hot pot. It's a popular choice for vegetarians and those looking for a light and healthy meal.\\n\\n3. Sushi: While Kyoto is not known for its sushi like other cities in Japan, you can still find some excellent sushi restaurants that use fresh, local ingredients.\\n\\n4. Yuba: A specialty of Kyoto, yuba is made from the skin that forms on top of heated soy milk. It can be enjoyed in various dishes such as yuba sushi or yuba hot pot.\\n\\n5. Matcha Green Tea: Kyoto is famous for its matcha green tea, so be sure to try a matcha-flavored dessert like matcha ice cream or matcha parfait.\\n\\nI hope these suggestions help you have a memorable culinary experience in Kyoto!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"I visited Kyomizu-dera before. I want to focus my day for the best cuisine in Kyoto. Give me some suggestions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "Based on the output, the conversational application has a memory now, and I have actually engaged in a conversation with the bot. However, there are two things which make the above code less suitable for real-life application. Firstly, the bot's behavior is rigid (\"The following is a friendly conversation between a human and an AI...\"). In a real-life scenario, we want to customize the bot's behavior, such as being attentive, cheerful, or thoughtful. Secondly, users often interact through a GUI, not through code like conversation.run(\"input_question\"). In the following code, I will address these issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1383/2173986566.py:28: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Dynamically construct the prompt that the model will see.\n",
    "# Customize the model's behavior (e.g. helpful, cheerful, or angry)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a helpful, cheerful, and attentive assistant that help the user to plan an optimized itinerary.\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),  # Dynamically inject the memory's conversation history into the prompt\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name\n",
    "# memory_key=\"chat_history\" links the memory to the MessagesPlaceholder, so the previous exchanges are injected into the prompt.\n",
    "# return_messages=True ensures that memory stores full messages (not just text) in a structured format, \n",
    "# which is necessary for the ChatPromptTemplate to include formatted message objects.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)\n",
    "conversation = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=False,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1383/2871464895.py:5: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = conversation({\"question\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  I want you to suggest some places for anime lovers in Kyoto.\n",
      "AI system:  Of course! Kyoto has several attractions that would appeal to anime lovers. Here are some places you might want to consider:\n",
      "\n",
      "1. **Toei Kyoto Studio Park**: This is a theme park where you can experience the world of traditional Japanese cinema and TV dramas. They have shows, exhibitions, and even activities where you can dress up as your favorite characters.\n",
      "\n",
      "2. **Kyoto International Manga Museum**: This museum is a must-visit for manga lovers. It houses a vast collection of manga from different eras and genres. You can spend hours browsing through the shelves and reading your favorite titles.\n",
      "\n",
      "3. **Arashiyama Bamboo Grove**: While not directly related to anime, this beautiful bamboo forest has been featured in several anime and movies. It's a great place to take pictures and immerse yourself in a serene and otherworldly atmosphere.\n",
      "\n",
      "4. **Fushimi Inari Taisha**: This shrine is famous for its thousands of vermillion torii gates that form a tunnel-like path up a mountain. It has been featured in numerous anime and is a popular spot for anime fans to visit.\n",
      "\n",
      "5. **Nishiki Market**: If you're a foodie anime lover, Nishiki Market is a great place to visit. You can try various traditional Japanese snacks and dishes that you might have seen in anime.\n",
      "\n",
      "Don't forget to check out any seasonal events or anime-related exhibitions happening during your visit to Kyoto. Enjoy your anime-themed adventure!\n",
      "User:  \n",
      "AI system:  If you have any more questions or need further assistance in planning your itinerary, feel free to ask! I'm here to help make sure you have a fantastic trip to Kyoto.\n",
      "User:  \n",
      "AI system:  If you have any specific preferences or requirements for your itinerary, feel free to let me know so I can tailor my recommendations accordingly. I'm here to assist you in planning a memorable trip to Kyoto!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input('You: ')\n",
    "    if query == 'quit':\n",
    "        break\n",
    "    output = conversation({\"question\": query})\n",
    "    print('User: ', query)\n",
    "    print('AI system: ', output['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question\n",
      "chat_history\n",
      "text\n"
     ]
    }
   ],
   "source": [
    "# (Only self-learning here)\n",
    "# The keys in output:\n",
    "# for key in output.keys():\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further self-learning\n",
    "Since the contents of the chat might be useful in the future, I will write code to save the whole chat history after quitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the conversation history after quitting\n",
    "# history = memory.buffer  # Access the conversation history\n",
    "\n",
    "# # Write to a text file\n",
    "# with open('conversation_history.txt', 'w') as file:\n",
    "#     for message in history:\n",
    "#         if isinstance(message, HumanMessage):\n",
    "#             file.write(f'User: {message.content}\\n')\n",
    "#         elif isinstance(message, AIMessage):\n",
    "#             file.write(f'AI system: {message.content}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other cases, I might want to use the chat history of a previous conversation as the context of a new chat. The following code allows me to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import (\n",
    "#     ChatPromptTemplate,\n",
    "#     MessagesPlaceholder,\n",
    "#     SystemMessagePromptTemplate,\n",
    "#     HumanMessagePromptTemplate,\n",
    "# )\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# # Step 1: Define the prompt\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     messages=[\n",
    "#         SystemMessagePromptTemplate.from_template(\n",
    "#             \"You are a helpful, cheerful, and attentive assistant that helps the user to plan an optimized itinerary.\"\n",
    "#         ),\n",
    "#         MessagesPlaceholder(variable_name=\"chat_history\"),  # Dynamically inject memory's conversation history\n",
    "#         HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Step 2: Load the saved chat history from the file\n",
    "# def load_chat_history(file_path):\n",
    "#     chat_history = []\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             if line.startswith('User:'):\n",
    "#                 chat_history.append(HumanMessage(content=line.strip().replace('User: ', '')))\n",
    "#             elif line.startswith('AI system:'):\n",
    "#                 chat_history.append(AIMessage(content=line.strip().replace('AI system: ', '')))\n",
    "#     return chat_history\n",
    "\n",
    "# # Load the chat history from the saved file\n",
    "# file_path = 'conversation_history.txt'\n",
    "# previous_chat_history = load_chat_history(file_path)\n",
    "\n",
    "# # Step 3: Create a new memory instance\n",
    "# new_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# # Step 4: Load the previous chat history into the new memory\n",
    "# for message in previous_chat_history:\n",
    "#     new_memory.save_context(message)\n",
    "\n",
    "# # Step 5: Create a new conversation with the loaded memory\n",
    "# new_conversation = LLMChain(\n",
    "#     llm=chat,\n",
    "#     prompt=prompt,\n",
    "#     verbose=False,\n",
    "#     memory=new_memory\n",
    "# )\n",
    "\n",
    "# # Start a new conversation\n",
    "# while True:\n",
    "#     query = input('You: ')\n",
    "#     if query == 'quit':\n",
    "#         break\n",
    "#     output = new_conversation({\"question\": query})\n",
    "#     print('User: ', query)\n",
    "#     print('AI system: ', output['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, I want to include multiple chat history files as the context of the new chat. In this situation, it is best to store the chat history files in a separate folder, which can be called \"chat_history\". The following code allows me to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import (\n",
    "#     ChatPromptTemplate,\n",
    "#     MessagesPlaceholder,\n",
    "#     SystemMessagePromptTemplate,\n",
    "#     HumanMessagePromptTemplate,\n",
    "# )\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# import glob\n",
    "\n",
    "# # Step 1: Define the prompt\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     messages=[\n",
    "#         SystemMessagePromptTemplate.from_template(\n",
    "#             \"You are a helpful, cheerful, and attentive assistant that helps the user to plan an optimized itinerary.\"\n",
    "#         ),\n",
    "#         MessagesPlaceholder(variable_name=\"chat_history\"),  # Dynamically inject memory's conversation history\n",
    "#         HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Step 2: Load chat history from multiple files\n",
    "# def load_chat_history(file_paths):\n",
    "#     chat_history = []\n",
    "#     for file_path in file_paths:\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             for line in file:\n",
    "#                 if line.startswith('User:'):\n",
    "#                     chat_history.append(HumanMessage(content=line.strip().replace('User: ', '')))\n",
    "#                 elif line.startswith('AI system:'):\n",
    "#                     chat_history.append(AIMessage(content=line.strip().replace('AI system: ', '')))\n",
    "#     return chat_history\n",
    "\n",
    "# # Step 3: Specify the directory and file pattern for loading chat history\n",
    "# directory_path = 'path_to_chat_history_directory'  \n",
    "# file_pattern = '*.txt'\n",
    "# file_paths = glob.glob(f\"{directory_path}/{file_pattern}\")\n",
    "\n",
    "# # Load the chat history from the specified files\n",
    "# previous_chat_history = load_chat_history(file_paths)\n",
    "\n",
    "# # Step 4: Create a new memory instance\n",
    "# new_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# # Step 5: Load the previous chat history into the new memory\n",
    "# for message in previous_chat_history:\n",
    "#     new_memory.save_context(message)\n",
    "\n",
    "# # Step 6: Create a new conversation with the loaded memory\n",
    "# new_conversation = LLMChain(\n",
    "#     llm=chat,\n",
    "#     prompt=prompt,\n",
    "#     verbose=False,\n",
    "#     memory=new_memory\n",
    "# )\n",
    "\n",
    "# # Start a new conversation\n",
    "# while True:\n",
    "#     query = input('You: ')\n",
    "#     if query == 'quit':\n",
    "#         break\n",
    "#     output = new_conversation({\"question\": query})\n",
    "#     print('User: ', query)\n",
    "#     print('AI system: ', output['text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
